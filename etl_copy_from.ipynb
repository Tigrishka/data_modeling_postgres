{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#process_data(cur, conn, filepath='data/song_data', func=process_song_file)\n",
    "#process_data(cur, conn, filepath='data/log_data', func=process_log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_files = get_files('data/song_data')\n",
    "#song_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepath = song_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "def process_song_file(song_files):\n",
    "    all_song_files = []\n",
    "    for song_f in song_files:\n",
    "        df = pd.read_json(song_f, lines=True)\n",
    "        all_song_files.append(df)\n",
    "    song_files_concat = pd.concat(all_song_files).drop_duplicates('song_id').drop_duplicates('artist_id').replace(np.nan, 0)\n",
    "#    song_files_concat['artist_latitude'] = song_files_concat['artist_latitude'].apply(lambda x: None if np.isnan(x) else x)\n",
    "#    song_files_concat['artist_longitude'] = song_files_concat['artist_longitude'].apply(lambda x: None if np.isnan(x) else x)\n",
    "    return song_files_concat\n",
    "\n",
    "def songs_table(song_files_list, cur):\n",
    "    song_files_fields = song_files_list[['song_id', 'title', 'artist_id', 'year', 'duration']]\n",
    "#    print(song_files_fields)\n",
    "    song_files_csv = song_files_fields.to_csv(header=False, sep='|', index=False)\n",
    "#    print(song_files_csv)\n",
    "    csv_file_like_object = io.StringIO()\n",
    "    csv_file_like_object.write(song_files_csv)\n",
    "    csv_file_like_object.seek(0)\n",
    "    cur.copy_from(csv_file_like_object, 'songs', sep='|')\n",
    "    conn.commit()\n",
    "\n",
    "def artists_table(song_files_list, cur):\n",
    "    song_files_fields = song_files_list[['artist_id','artist_name','artist_location','artist_latitude','artist_longitude']]\n",
    "#    print(song_files_fields)\n",
    "    song_files_csv = song_files_fields.to_csv(header=False, sep='|', index=False)\n",
    "#    print(song_files_csv)\n",
    "    csv_file_like_object = io.StringIO()\n",
    "    csv_file_like_object.write(song_files_csv)\n",
    "    csv_file_like_object.seek(0)\n",
    "    cur.copy_from(csv_file_like_object, 'artists', sep='|')\n",
    "    conn.commit()\n",
    "\n",
    "song_files_list = process_song_file(song_files)\n",
    "song_files_list\n",
    "songs_table(song_files_list,cur)\n",
    "artists_table(song_files_list, cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_files = get_files('data/log_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_log_file(log_files):\n",
    "    all_log_files = []\n",
    "    for log_f in log_files:\n",
    "        df = pd.read_json(log_f, lines=True)\n",
    "        t = pd.to_datetime(df['ts'], unit='ms').dt.round('S')\n",
    "        df['start_time'] = t\n",
    "        df['hour'] = t.dt.hour\n",
    "        df['day'] = t.dt.day\n",
    "        df['week'] = t.dt.week\n",
    "        df['month'] = t.dt.month\n",
    "        df['year'] = t.dt.year\n",
    "        df['weekday'] = t.dt.weekday\n",
    "        all_log_files.append(df)\n",
    "    log_files_concat = pd.concat(all_log_files)\n",
    "    log_files_concat = log_files_concat.loc[log_files_concat['page']=='NextSong']  \n",
    "    return log_files_concat\n",
    "\n",
    "def log_files_staging_table(log_files_list, cur):\n",
    "    log_files_fields = log_files_list[['start_time','hour','day','week','month','year','weekday',\n",
    "                                       'userId','firstName','lastName','gender','level','artist',\n",
    "                                       'song','length','sessionId','location','userAgent']]\n",
    "    log_files_csv = log_files_fields.to_csv(header=False, sep='|', index=False)\n",
    "    csv_file_like_object = io.StringIO()\n",
    "    csv_file_like_object.write(log_files_csv)\n",
    "    csv_file_like_object.seek(0)\n",
    "    cur.copy_from(csv_file_like_object, 'log_files_staging', sep='|')\n",
    "    conn.commit()\n",
    "    \n",
    "\"\"\"\n",
    "def time_table(log_files_list, cur):\n",
    "    t = pd.to_datetime(log_files_list['ts'], unit='ms').dt.round('S')\n",
    "    time_data = [t, t.dt.hour, t.dt.day, t.dt.weekofyear, t.dt.month, t.dt.year, t.dt.weekday]\n",
    "    column_labels = ['start_time', 'hour', 'day', 'week', 'month', 'year', 'weekday']\n",
    "    time_df = pd.DataFrame(dict(zip(column_labels, time_data))).drop_duplicates('start_time')\n",
    "#    print(time_df)\n",
    "    log_files_csv = time_df.to_csv(header=False, sep='|', index=False)\n",
    "    csv_file_like_object = io.StringIO()\n",
    "    csv_file_like_object.write(log_files_csv)\n",
    "    csv_file_like_object.seek(0)\n",
    "    cur.copy_from(csv_file_like_object, 'time', sep='|')\n",
    "    conn.commit()\n",
    "\n",
    "def user_table(log_files_list, cur):\n",
    "    user_df = log_files_list[['userId','firstName','lastName','gender','level']]\n",
    "#    print(user_df)\n",
    "    log_files_csv = user_df.to_csv(header=False, sep='|', index=False)\n",
    "#    print(log_files_csv)\n",
    "    csv_file_like_object = io.StringIO()\n",
    "    csv_file_like_object.write(log_files_csv)\n",
    "    csv_file_like_object.seek(0)\n",
    "    cur.copy_from(csv_file_like_object, 'users', sep='|')\n",
    "    conn.commit()\n",
    "\"\"\"\n",
    "\n",
    "log_files_list = process_log_file(log_files)\n",
    "#print(log_files_list)\n",
    "log_files_staging_table(log_files_list, cur)\n",
    "#time_table(log_files_list, cur)\n",
    "#user_table(log_files_list, cur)\n",
    "cur.execute(time_table_staging_insert)\n",
    "conn.commit()\n",
    "cur.execute(merge_user_table)\n",
    "conn.commit()\n",
    "cur.execute(songplay_table_staging_insert)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
